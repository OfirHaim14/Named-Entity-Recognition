{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL_M1evVOv5v"
      },
      "source": [
        "# **NLP- Homework 2**\n",
        "*Ofir Haim ID 213496110*\n",
        "\n",
        "*Maor Dikter ID 214169377*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa2BNNBsm_JI"
      },
      "source": [
        "### **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "fPUdnJAR4JWg",
        "outputId": "35d3ae5a-c35c-4770-9cfb-b32646cb9cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: gensim 4.2.0\n",
            "Uninstalling gensim-4.2.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.8/dist-packages/gensim-4.2.0.dist-info/*\n",
            "    /usr/local/lib/python3.8/dist-packages/gensim/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled gensim-4.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gensim==4.2.0\n",
            "  Using cached gensim-4.2.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from gensim==4.2.0) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim==4.2.0) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from gensim==4.2.0) (1.21.6)\n",
            "Installing collected packages: gensim\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gensim"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall gensim\n",
        "!pip install --upgrade gensim==4.2.0\n",
        "#we had a problem because the version wasn't the new one so we uninstalled it and downloaded the new one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "Oh4BAJMC6ciI"
      },
      "outputs": [],
      "source": [
        "# Data processing and visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv, re, tqdm\n",
        "\n",
        "# sklearn\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim import downloader\n",
        "\n",
        "# Imbalanced learning\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Pickle\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "tdS1HmY0njkP"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PREn7l_nIj1"
      },
      "source": [
        "\n",
        "### **Load our data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "4VHQsFF9ntBP"
      },
      "outputs": [],
      "source": [
        "# for convenience reasons we save the paths for every file here\n",
        "TRAIN_PATH = './data/train.tagged'\n",
        "DEV_PATH = './data/dev.tagged'\n",
        "TEST_PATH = './data/test.untagged'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "iab5asdQpT_Q"
      },
      "outputs": [],
      "source": [
        "model = downloader.load('glove-twitter-200') # download glove"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps3a2GZCxZUN"
      },
      "source": [
        "### **Extracting relevant data from a file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "IMasNz4MDxc1"
      },
      "outputs": [],
      "source": [
        "def get_X_Y(data_path):\n",
        "  \"\"\"\n",
        "  the function gets the processed corpus and extract from it all the words and gets their\n",
        "  word2vec representation. It also gets the matching tag values for each word and\n",
        "  return the words embedding and their representation.\n",
        "  \"\"\"\n",
        "  vecs = []\n",
        "  relevant_idx = []\n",
        "  for idx, word in enumerate(data_path):\n",
        "    if model.has_index_for(word):\n",
        "      vecs.append(model.get_vector(word))\n",
        "      relevant_idx.append(idx)\n",
        "    elif model.has_index_for(word.lower()):\n",
        "      vecs.append(model.get_vector(word.lower()))\n",
        "      relevant_idx.append(idx)\n",
        "\n",
        "  x = np.array(vecs)\n",
        "  # Note that y = labels[relevant_idx] when exists\n",
        "  return x, relevant_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4xEg5deCixj"
      },
      "source": [
        "### **Writing results into file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "J2VC82EFCtF5"
      },
      "outputs": [],
      "source": [
        "def write_results_to_file(original_path, new_path, words, y_preds):\n",
        "    \"\"\"\n",
        "    This function writes the predictions of the different models on a new file,\n",
        "    following the required guidelines of the file.\n",
        "    \"\"\"\n",
        "    src_f = open(original_path, 'r')\n",
        "    lines = np.array(src_f.readlines())\n",
        "    # Check for spaces in the original file\n",
        "    source_file_spaces_idx = np.where(lines == '\\n')[0]\n",
        "    \n",
        "    f = open(new_path, 'w', encoding=\"utf-8\")\n",
        "    y_preds_file = np.where(y_preds == 0, 'O', y_preds)\n",
        "    \n",
        "    idx = 0\n",
        "    for word, pred in zip(words, y_preds_file):\n",
        "        if idx in source_file_spaces_idx:\n",
        "            f.write('\\n') # Add spaces to our file\n",
        "            idx += 1\n",
        "        f.write('{}\\t{}\\n'.format(str(word), pred))\n",
        "        idx += 1\n",
        "    if idx in source_file_spaces_idx:\n",
        "        f.write('\\n')\n",
        "        idx += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCwBQzQsN-Fi"
      },
      "source": [
        "## **Process the files**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzR1yZLuxCmM"
      },
      "source": [
        "### **Process the Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "NbcFi7SJpxZv"
      },
      "outputs": [],
      "source": [
        "# Load training data\n",
        "train_data_raw = pd.read_csv(TRAIN_PATH, sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
        "train_data_raw.columns = ['words', 'tags']\n",
        "# Pereprocess corpus\n",
        "train_corpus = train_data_raw['words'].to_numpy()\n",
        "# Remove non alphanumerical chars\n",
        "processed_train_corpus = np.array([re.sub(r'[^a-zA-Z0-9]', '', str(word)) for word in train_corpus])\n",
        "train_labels = train_data_raw['tags'].to_numpy()\n",
        "train_labels = np.where(train_labels == 'O', 0, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "OjF38FJxbf6U"
      },
      "outputs": [],
      "source": [
        "X_train, relevant_idx_train = get_X_Y(processed_train_corpus)\n",
        "y_train = train_labels[relevant_idx_train]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drC7TJC5AHVa"
      },
      "source": [
        "### **Process the Dev**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "VtBJIk1OAF88"
      },
      "outputs": [],
      "source": [
        "# read the dev file and save the words, tags in numpy arrays for future use\n",
        "dev = pd.read_csv(DEV_PATH, sep='\\t', header=None, quoting=csv.QUOTE_NONE) \n",
        "dev.columns = ['words', 'tags']\n",
        "dev_corpus = dev['words'].to_numpy(dtype=str)\n",
        "# Remove non alphanumerical chars\n",
        "processed_dev_corpus = np.array([re.sub(r'[^a-zA-Z0-9]', '', word) for word in dev_corpus]) \n",
        "dev_tags = dev['tags'].to_numpy()\n",
        "dev_tags = np.where(dev_tags == 'O', 0, 1) # we do binary classification between 'o' and the other tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "x4Hhf48qzEL7"
      },
      "outputs": [],
      "source": [
        "x_dev, relevant_idx_dev = get_X_Y(processed_dev_corpus)\n",
        "y_dev = dev_tags[relevant_idx_dev]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHJO-Hecx6HT"
      },
      "source": [
        "### **Process the Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "TGxf5Ed3x5eO"
      },
      "outputs": [],
      "source": [
        "# Prepare the test-set\n",
        "test_data_raw = pd.read_csv(TEST_PATH, sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
        "test_data_raw.columns = ['words']\n",
        "test_corpus = test_data_raw['words'].to_numpy(dtype=str)\n",
        "processed_test_corpus = np.array([re.sub(r'[^a-zA-Z0-9]', '', word) for word in test_corpus]) # remove non alphanumerical chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "Lij5t4CP07ip"
      },
      "outputs": [],
      "source": [
        "x_test, relevant_idx_test = get_X_Y(processed_test_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfoVqvpTMG_4"
      },
      "source": [
        "## **Model1 - SVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDYfxVs2negV",
        "outputId": "2955be47-3caa-4b3c-c296-4d8d697202af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "linear_model = SVC()\n",
        "#train the SVM model on the train file\n",
        "linear_model.fit(X_train, y_train) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-FvIL0_wssv"
      },
      "source": [
        "### **Model1 - SVM test on train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDHkNCwoYff1",
        "outputId": "9b3c1608-04a1-4083-fe4e-e0d645b5cb77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: the f1 score is:  0.8358870967741935\n"
          ]
        }
      ],
      "source": [
        "# Model prediction on train\n",
        "pred = linear_model.predict(X_train) \n",
        "y_train_pred_svm = np.zeros(train_labels.size, dtype=int)\n",
        "# Prediction on all tags- not just the relevant ones\n",
        "y_train_pred_svm[relevant_idx_train] = pred\n",
        "# F1 score calculation\n",
        "f1 = f1_score(train_labels, y_train_pred_svm)\n",
        "print(\"Train: the f1 score is: \", f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nolCup-wxRA"
      },
      "source": [
        "### **Model1 - SVM test on dev**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BCykJFfqmwE",
        "outputId": "1015ac68-5b9b-4e84-bdd6-b290b01b817b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev: the f1 score is:  0.5515320334261838\n"
          ]
        }
      ],
      "source": [
        "# Model prediction on dev\n",
        "pred = linear_model.predict(x_dev) \n",
        "y_dev_pred_svm = np.zeros(dev_tags.size, dtype=int)\n",
        "# Prediction on all tags- not just the relevant ones\n",
        "y_dev_pred_svm[relevant_idx_dev] = pred\n",
        "# F1 score calculation\n",
        "f1 = f1_score(dev_tags, y_dev_pred_svm)\n",
        "print(\"Dev: the f1 score is: \", f1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wozUhbtWTAjg",
        "outputId": "f6df62da-1fe1-4ece-a676-73a4ab16c428"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14434,    49],\n",
              "       [  756,   495]])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "con_mat = confusion_matrix(dev_tags, y_dev_pred_svm)\n",
        "con_mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fUKLoB3Mf6W"
      },
      "source": [
        "## **Model2 - NN**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "JeZyXrOMrw_c"
      },
      "outputs": [],
      "source": [
        "class FFNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FFNetwork, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(200, 80),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(80, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 1))\n",
        "        self.prediction = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return self.prediction(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yboY1oefq1f"
      },
      "source": [
        "### **Train the FFN**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "-1_SK0zAr0Hk"
      },
      "outputs": [],
      "source": [
        "# Batch size and number of epochs\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "# Loading the dataset\n",
        "dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
        "trainloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Choose gpu if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
        "# Connect the nn to the cpu\n",
        "ff = FFNetwork().to(device)\n",
        "# Defining out loss- Binary Cross Entropy \n",
        "loss_function = nn.BCELoss()\n",
        "#optimizer = optim.Adam(ff.parameters())\n",
        "# We chose stochastic gradiant decent as the optimization method\n",
        "optimizer = torch.optim.SGD(ff.parameters(), lr = 0.03) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d6dIw7KupvA",
        "outputId": "d70a2962-f2a0-49d9-a2be-8245e066fcb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [00:00<00:00, 969.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \t\t Training Loss: 0.20436863150080195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [00:00<00:00, 948.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 \t\t Training Loss: 0.13451913989075784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [00:00<00:00, 991.04it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 \t\t Training Loss: 0.12312882672413979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [00:00<00:00, 968.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 \t\t Training Loss: 0.11856653993616761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [00:00<00:00, 1007.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 \t\t Training Loss: 0.11545220279389441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [00:00<00:00, 1005.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 \t\t Training Loss: 0.11299492968025428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [00:00<00:00, 988.68it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 \t\t Training Loss: 0.11070808804199825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [00:00<00:00, 1030.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 \t\t Training Loss: 0.10841988230568267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [00:00<00:00, 1004.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 \t\t Training Loss: 0.10655491331594527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [00:00<00:00, 999.57it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 \t\t Training Loss: 0.1045380730133099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for e in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    for data, labels in tqdm.tqdm(trainloader):\n",
        "        # Transfer Data to GPU if available\n",
        "        #if torch.cuda.is_available():\n",
        "            # data, labels = data.cuda(), labels.cuda()\n",
        "        data = data.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Forward Pass\n",
        "        target = ff.forward(data)\n",
        "        # Find the Loss\n",
        "        loss = loss_function(target,labels.view(-1,1))\n",
        "        # Calculate gradients\n",
        "        loss.backward()\n",
        "        # Update Weights\n",
        "        optimizer.step()\n",
        "        # Calculate Loss\n",
        "        train_loss += loss.item()\n",
        "    print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / len(trainloader)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYL27_riwgdm"
      },
      "source": [
        "### **Model2 - NN test on train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SxXG57Kum47",
        "outputId": "dc7a6e75-4e05-43c7-cb79-af55ffb65711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: the f1 score is:  0.8077427159995967\n"
          ]
        }
      ],
      "source": [
        "# Test model on the train set\n",
        "X_train_tensor = torch.from_numpy(X_train).type(torch.float)\n",
        "X_train_tensor = X_train_tensor.to(device)\n",
        "with torch.no_grad():\n",
        "  predictions = ff.forward(X_train_tensor)\n",
        "  predictions = predictions.to(device)\n",
        "  predictions = np.where(predictions > 0.5, 1, 0).reshape(-1)\n",
        "\n",
        "y_train_pred_nn = np.zeros(train_labels.size, dtype=int)\n",
        "y_train_pred_nn[relevant_idx_train] = predictions\n",
        "# F1 score calculation\n",
        "f1 = f1_score(train_labels, y_train_pred_nn)\n",
        "print(\"Train: the f1 score is: \", f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGUnfLrRgMnM"
      },
      "source": [
        "### **Model2 - NN test  on dev**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQBniniRgLcf",
        "outputId": "67a4004f-3741-435d-bb5f-7a3c9d01c91c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev: the f1 score is:  0.5467314964883847\n"
          ]
        }
      ],
      "source": [
        "X_dev_tensor = torch.from_numpy(x_dev).type(torch.float)\n",
        "X_dev_tensor = X_dev_tensor.to(device)\n",
        "with torch.no_grad():\n",
        "  predictions = ff.forward(X_dev_tensor)\n",
        "  predictions = predictions.to(device)\n",
        "  predictions = np.where(predictions > 0.5, 1, 0).reshape(-1)\n",
        "\n",
        "y_dev_pred_nn = np.zeros(dev_tags.size, dtype=int)\n",
        "y_dev_pred_nn[relevant_idx_dev] = predictions\n",
        "# F1 score calculation\n",
        "f1 = f1_score(dev_tags, y_dev_pred_nn)\n",
        "print(\"Dev: the f1 score is: \", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCNh4WEHSn5q",
        "outputId": "43e8879d-d1e6-4d97-e284-74b893d0baa0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14389,    94],\n",
              "       [  745,   506]])"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "con_mat = confusion_matrix(dev_tags, y_dev_pred_nn)\n",
        "con_mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj7Px-cvPSCQ"
      },
      "source": [
        "## **Model 3 - LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zCaV4EEuXcf"
      },
      "source": [
        "### **Pickle functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "3_ltnFnWua-G"
      },
      "outputs": [],
      "source": [
        "def save_linear_model(path, model):\n",
        "    pickle.dump(model, open(path, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEsfS1xvkqY2"
      },
      "source": [
        "### **Train preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "y8duHaZbk072"
      },
      "outputs": [],
      "source": [
        "def is_begin_tweet(word):\n",
        "  # checking if a word is the start of the tweet \n",
        "  word = str(word)\n",
        "  return len(word) > 0 and word[0] == '@'\n",
        "tweet_start_mask = np.vectorize(is_begin_tweet)\n",
        "is_tweet_start = tweet_start_mask(train_corpus)\n",
        "tweet_start_idx = np.where(is_tweet_start)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "68kirqLlphzI"
      },
      "outputs": [],
      "source": [
        "def get_X_Y_with_features(processed_data_path, data_path):\n",
        "  vecs = []\n",
        "  for idx, word in enumerate(processed_data_path):\n",
        "    original_word = data_path[idx]\n",
        "    if idx in tweet_start_idx:\n",
        "        vecs.append(tweet_start_token)\n",
        "    elif original_word == '.':\n",
        "        vecs.append(eos_token)\n",
        "    elif original_word == ',':\n",
        "        vecs.append(comma_token)\n",
        "    elif original_word == '\"':\n",
        "        vecs.append(quotes_token)\n",
        "    elif model.has_index_for(word):\n",
        "        vecs.append(model.get_vector(word))\n",
        "    elif model.has_index_for(word.lower()):\n",
        "        vecs.append(model.get_vector(word.lower()))\n",
        "    else:\n",
        "        vecs.append(np.zeros(200))\n",
        "  x = np.array(vecs)\n",
        "  return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "I8yVTG8Po6Jf"
      },
      "outputs": [],
      "source": [
        "# for the competetive part we will use a new train  data\n",
        "tweet_start_token = np.random.randn(200)\n",
        "eos_token = np.random.randn(200)\n",
        "comma_token = np.random.randn(200)\n",
        "quotes_token = np.random.randn(200)\n",
        "\n",
        "X_train = get_X_Y_with_features(processed_train_corpus, train_corpus)\n",
        "y_train = train_labels\n",
        "\n",
        "# saving the tokens for future use\n",
        "token_list = [tweet_start_token, eos_token, comma_token, quotes_token]\n",
        "np.save('./tokens.npy', token_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po-3p-5a0XCE"
      },
      "source": [
        "**Creating a feature for words with capital letters - Excluding the ones in the beginning of a sentence**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "BBUHDLmL0dRc"
      },
      "outputs": [],
      "source": [
        "def is_capitalized(previous_word, word):\n",
        "  # Check if  words that appear in the middle of the sentence are captilized\n",
        "  previous_word = str(previous_word)\n",
        "  word = str(word)\n",
        "  return previous_word != '.' and len(word) > 0 and (word[0] != word[0].lower())\n",
        "capitalization_mask = np.vectorize(is_capitalized)\n",
        "is_capitalized_vec = capitalization_mask(train_corpus[:-1], train_corpus[1:])\n",
        "is_capitalized_vec = np.concatenate(([np.False_], is_capitalized_vec))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSBdgzEA5GV5",
        "outputId": "ba86dfd3-4d4d-412d-a8f1-e72593dae9b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65124, 201)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "# Add the begin tweet & capitalization feature\n",
        "capitalized_feature = is_capitalized_vec.astype(float).reshape(-1,1)\n",
        "\n",
        "X_train_new = np.append(X_train, capitalized_feature, axis = 1)\n",
        "X_train_new.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEodb5-cB8u9"
      },
      "source": [
        "**In this model we would like to consider the type of tag, instead of the previous ones in which we had only 0 and 1.**\n",
        "\n",
        "**We will sort them by their category**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "kDKDdZjy9EkL"
      },
      "outputs": [],
      "source": [
        "# Visualize the distribution of all the positive tags in the train set\n",
        "def group_positive_tags(tag):\n",
        "  tag = str(tag)\n",
        "  if tag != 'O':\n",
        "    return tag[2:]\n",
        "  return tag\n",
        "fixed_tags = train_data_raw['tags'].apply(lambda x: group_positive_tags(x))\n",
        "\n",
        "# Find all the descriptive labels of the new training data\n",
        "descriptive_labels = fixed_tags.to_numpy()\n",
        "\n",
        "# Convert the binary labels to integer labels according to the various catrgories\n",
        "categories = np.unique(np.copy(descriptive_labels))\n",
        "for idx, category in enumerate(categories):\n",
        "    category_idx = np.where(descriptive_labels == category)[0]\n",
        "    descriptive_labels[category_idx] = idx\n",
        "\n",
        "y_train_new = descriptive_labels.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUylmTzMC40w"
      },
      "source": [
        "**Creating sentences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "Pa6gBC-cC7QE"
      },
      "outputs": [],
      "source": [
        "# Generate a list of sentences to feed the sequential model\n",
        "sentences = []\n",
        "current_sentence = []\n",
        "sentences_labels = []\n",
        "current_labels = []\n",
        "\n",
        "for idx, word_embedding in enumerate(X_train_new):\n",
        "    if all(word_embedding[:-1] == tweet_start_token):\n",
        "        if len(current_sentence) > 0:\n",
        "            current_sentence = np.array(current_sentence)\n",
        "            current_sentence = torch.tensor(current_sentence)\n",
        "            # New shape is: (1,L,E) == batch_first\n",
        "            current_sentence = current_sentence.reshape((1, current_sentence.shape[0], current_sentence.shape[1]))\n",
        "            sentences.append(current_sentence)\n",
        "            current_labels = torch.tensor(np.array(current_labels))\n",
        "            sentences_labels.append(current_labels)\n",
        "        current_sentence = [word_embedding]\n",
        "        current_labels = [y_train_new[idx]]\n",
        "    else:\n",
        "        current_sentence.append(word_embedding)\n",
        "        current_labels.append(y_train_new[idx])\n",
        "\n",
        "current_sentence = np.array(current_sentence)\n",
        "current_sentence = torch.tensor(current_sentence)\n",
        "# New shape is: (1,L,E) == batch_first\n",
        "current_sentence = current_sentence.reshape((1, current_sentence.shape[0], current_sentence.shape[1]))\n",
        "sentences.append(current_sentence)\n",
        "current_labels = torch.tensor(np.array(current_labels))\n",
        "sentences_labels.append(current_labels)\n",
        "\n",
        "sentences_labels_binary = []\n",
        "for sentence_labels in sentences_labels:\n",
        "    sentences_labels_binary.append(torch.tensor(np.where(sentence_labels == 0, 0, 1)).double())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A42Gz9vMFLoN"
      },
      "source": [
        "### **Define the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "8w5KHsjkfdxa"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size=201, hidden_size=100, num_of_categories=11, mlp_mid_size=50):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, num_layers=2, hidden_size=hidden_size//2, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_size,hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, mlp_mid_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(mlp_mid_size, num_of_categories)\n",
        "        )\n",
        "        self.binary_fc = nn.Sequential(\n",
        "            nn.Linear(num_of_categories, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input_sequence):\n",
        "        lstm_hidden, _ = self.lstm(input_sequence)\n",
        "        out_1 = self.fc(lstm_hidden)\n",
        "        out_2 = self.binary_fc(out_1)\n",
        "        return out_1, out_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMumojV4C0bc"
      },
      "source": [
        "### **Train the network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgIX_iiVC3xt",
        "outputId": "be61b4b3-fa6b-41a1-98e2-0eca35edb1d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [11:30<00:00, 49.31s/it]\n"
          ]
        }
      ],
      "source": [
        "# Define CPU or GPU device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "network = LSTMModel().to(device)\n",
        "network = network.double()\n",
        "\n",
        "# Loss function and Optimizer\n",
        "loss_fn_1 = nn.CrossEntropyLoss()\n",
        "loss_fn_2 = nn.BCELoss()\n",
        "optimizer = optim.Adam(network.parameters())\n",
        "\n",
        "# Train the network\n",
        "epochs = 14\n",
        "lamda = 2e-1\n",
        "\n",
        "for epoch in tqdm.tqdm(range(epochs)):\n",
        "  for sequence, full_targets, binary_targets in zip(sentences, sentences_labels, sentences_labels_binary):\n",
        "    sequence = sequence.double()\n",
        "    sequence = sequence.to(device)\n",
        "    full_targets = full_targets.to(device)\n",
        "    binary_targets = binary_targets.to(device)\n",
        "    sequence_len = sequence.shape[1]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    full_preds, binary_preds = network.forward(sequence)\n",
        "    loss_1 = loss_fn_1(full_preds.view((sequence_len,-1)), full_targets.type(torch.long))\n",
        "    loss_2 = loss_fn_2(binary_preds.view((sequence_len,-1)), binary_targets.view((sequence_len, -1)))\n",
        "    loss = lamda * loss_1 + loss_2\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "41JmiSN7DlNd"
      },
      "outputs": [],
      "source": [
        "# Save the trained model to file\n",
        "torch.save(network.state_dict(), './TrainedLSTM.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpLZiNHcKeX_"
      },
      "source": [
        "### **Dev preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "byNCox1YKj-W"
      },
      "outputs": [],
      "source": [
        "# Get tweet start indices in dev\n",
        "is_tweet_start_dev = tweet_start_mask(dev_corpus)\n",
        "tweet_start_idx_dev = np.where(is_tweet_start_dev)[0]\n",
        "\n",
        "X_dev = get_X_Y_with_features(processed_dev_corpus, dev_corpus)\n",
        "y_dev = dev_tags\n",
        "\n",
        "# Get the indecies of capitlized words that appear in the middle of the sentence\n",
        "is_capitalized_vec_dev = capitalization_mask(dev_corpus[:-1], dev_corpus[1:])\n",
        "is_capitalized_vec_dev = np.concatenate(([np.False_], is_capitalized_vec_dev))\n",
        "\n",
        "# Add the begin tweet & capitalization feature\n",
        "capitalized_feature_dev = is_capitalized_vec_dev.astype(float).reshape(-1,1)\n",
        "X_dev_new = np.append(X_dev, capitalized_feature_dev, axis=1)\n",
        "\n",
        "# Find all the descriptive labels of the new training data\n",
        "dev_descriptive_labels = dev['tags'].to_numpy()\n",
        "group_positive_tags_vec = np.vectorize(group_positive_tags)\n",
        "dev_descriptive_labels = group_positive_tags_vec(dev_descriptive_labels)\n",
        "\n",
        "# Convert the binary labels to integer labels according to the various catrgories\n",
        "for idx, category in enumerate(categories):\n",
        "    dev_category_idx = np.where(dev_descriptive_labels == category)[0]\n",
        "    dev_descriptive_labels[dev_category_idx] = idx\n",
        "y_dev_new = dev_descriptive_labels.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "tqJVVCvxRZuN"
      },
      "outputs": [],
      "source": [
        "# Generate a list of sentences to feed the sequential model\n",
        "dev_sentences = []\n",
        "current_sentence = []\n",
        "dev_sentences_labels = []\n",
        "current_labels = []\n",
        "\n",
        "for idx, word_embedding in enumerate(X_dev_new):\n",
        "    if all(word_embedding[:-1] == tweet_start_token):\n",
        "        if len(current_sentence) > 0:\n",
        "            current_sentence = np.array(current_sentence)\n",
        "            current_sentence = torch.tensor(current_sentence)\n",
        "             # New shape is: (1,L,E) == batch_first\n",
        "            current_sentence = current_sentence.reshape((1, current_sentence.shape[0], current_sentence.shape[1]))\n",
        "            dev_sentences.append(current_sentence)\n",
        "            current_labels = torch.tensor(np.array(current_labels))\n",
        "            dev_sentences_labels.append(current_labels)\n",
        "        current_sentence = [word_embedding]\n",
        "        current_labels = [y_dev_new[idx]]\n",
        "    else:\n",
        "        current_sentence.append(word_embedding)\n",
        "        current_labels.append(y_dev_new[idx])\n",
        "\n",
        "current_sentence = np.array(current_sentence)\n",
        "current_sentence = torch.tensor(current_sentence)\n",
        " # New shape is: (1,L,E) == batch_first\n",
        "current_sentence = current_sentence.reshape((1, current_sentence.shape[0], current_sentence.shape[1]))\n",
        "dev_sentences.append(current_sentence)\n",
        "current_labels = torch.tensor(np.array(current_labels))\n",
        "dev_sentences_labels.append(current_labels)\n",
        "\n",
        "dev_sentences_labels_binary = []\n",
        "for sentence_labels in dev_sentences_labels:\n",
        "    dev_sentences_labels_binary.append(torch.tensor(np.where(sentence_labels == 0, 0, 1)).double())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twf81r3bRoas"
      },
      "source": [
        "### **Model 3- test on Dev**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1hrZfZ1Ruw7",
        "outputId": "25b09459-f18a-4dc7-9fd5-347cae6dfc38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 414/414 [00:01<00:00, 250.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev: the f1 score is:  0.6164102564102564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the predictions on test set and print the results\n",
        "tot_preds = []\n",
        "with torch.no_grad():\n",
        "  for sequence in tqdm.tqdm(dev_sentences):\n",
        "    sequence = sequence.double()\n",
        "    sequence = sequence.to(device)\n",
        "    sequence_len = sequence.shape[1]\n",
        "    _, binary_preds = network.forward(sequence)\n",
        "    predictions = list(np.where(binary_preds > 0.5, 1, 0).reshape(-1))\n",
        "    tot_preds += predictions\n",
        "comp_dev_all_preds = tot_preds\n",
        "f1 = f1_score(dev_tags, comp_dev_all_preds)\n",
        "print(\"Dev: the f1 score is: \", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2bepn6-UW2-",
        "outputId": "f880adfb-9da8-4c5a-e2a8-155ea047a615"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14385,    98],\n",
              "       [  650,   601]])"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ],
      "source": [
        "con_mat = confusion_matrix(dev_tags, comp_dev_all_preds)\n",
        "con_mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at48GEPwSsT7"
      },
      "source": [
        "### **Test preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "eCsX0kIvSrzG"
      },
      "outputs": [],
      "source": [
        "# Get tweet start indices\n",
        "is_tweet_start_test = tweet_start_mask(test_corpus)\n",
        "tweet_start_idx_test = np.where(is_tweet_start_test)[0]\n",
        "X_test = get_X_Y_with_features(processed_test_corpus, test_corpus)\n",
        "\n",
        "# Get the indecies of capitlized words that appear in the middle of the sentence\n",
        "is_capitalized_vec_test = capitalization_mask(test_corpus[:-1], test_corpus[1:])\n",
        "is_capitalized_vec_test = np.concatenate(([np.False_], is_capitalized_vec_test))\n",
        "\n",
        "# Add the begin tweet & capitalization feature\n",
        "capitalized_feature_test = is_capitalized_vec_test.astype(float).reshape(-1,1)\n",
        "X_test_new = np.append(X_test, capitalized_feature_test, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "OJGC3aRLTUBH"
      },
      "outputs": [],
      "source": [
        "# Generate a list of sentences to feed the sequential model\n",
        "test_sentences = []\n",
        "current_sentence = []\n",
        "for idx, word_embedding in enumerate(X_test_new):\n",
        "    if all(word_embedding[:-1] == tweet_start_token):\n",
        "        if len(current_sentence) > 0:\n",
        "            current_sentence = np.array(current_sentence)\n",
        "            current_sentence = torch.tensor(current_sentence)\n",
        "            current_sentence = current_sentence.reshape((1, current_sentence.shape[0], current_sentence.shape[1])) # New shape is: (1,L,E) == batch_first\n",
        "            test_sentences.append(current_sentence)\n",
        "        current_sentence = [word_embedding]\n",
        "    else:\n",
        "        current_sentence.append(word_embedding)\n",
        "\n",
        "current_sentence = np.array(current_sentence)\n",
        "current_sentence = torch.tensor(current_sentence)\n",
        "current_sentence = current_sentence.reshape((1, current_sentence.shape[0], current_sentence.shape[1])) # New shape is: (1,L,E) == batch_first\n",
        "test_sentences.append(current_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUNz_lFy96Iw"
      },
      "source": [
        "### **Model3 - prediction on test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-S2w1NETep2",
        "outputId": "9d2b5922-302d-467a-b659-51294f7493d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 613/613 [00:02<00:00, 249.86it/s]\n"
          ]
        }
      ],
      "source": [
        "# Get the predictions on test set and print the results\n",
        "tot_preds = []\n",
        "with torch.no_grad():\n",
        "  for sequence in tqdm.tqdm(test_sentences):\n",
        "    sequence = sequence.double()\n",
        "    sequence = sequence.to(device)\n",
        "    sequence_len = sequence.shape[1]\n",
        "\n",
        "    _, binary_preds = network.forward(sequence)\n",
        "    predictions = list(np.where(binary_preds > 0.5, 1, 0).reshape(-1))\n",
        "    tot_preds += predictions\n",
        "\n",
        "comp_test_all_preds = tot_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "owEmK5iF97FK"
      },
      "outputs": [],
      "source": [
        "write_results_to_file(TEST_PATH, './comp_213496110_214169377.tagged', test_corpus, comp_test_all_preds)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "x4xEg5deCixj",
        "SfoVqvpTMG_4",
        "6fUKLoB3Mf6W",
        "5zCaV4EEuXcf",
        "A42Gz9vMFLoN",
        "rMumojV4C0bc",
        "FpLZiNHcKeX_",
        "Twf81r3bRoas",
        "at48GEPwSsT7",
        "DUNz_lFy96Iw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}